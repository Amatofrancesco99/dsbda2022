{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spark located in /usr/local/spark/.\n"
     ]
    }
   ],
   "source": [
    "import findspark, sys\n",
    "\n",
    "# Locate the Spark installation (add pyspark to sys.path, see https://github.com/minrk/findspark#readme)\n",
    "findspark.init()\n",
    "print(f'Using Spark located in {findspark.find()}.')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create or get the Spark session (singleton) and the underlying Spark context\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps, nltk, pymongo, pandas as pd, re, sklearn, operator, numpy as np, seaborn as sb\n",
    "from pyspark.sql.functions import udf, col, size\n",
    "from pyspark.sql import functions as F, Window\n",
    "from pyspark.sql.types import BooleanType, DoubleType, LongType, StringType, StructField, StructType, IntegerType, ArrayType\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StopWordsRemover, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Hypothesis:\n",
    "\n",
    "In the following notebook the following hypothesis, already analyzed in local (using standard python), will be replicated on the Big Data source located in the HDFS:\n",
    " - **Does there exist a relationship between the text of the review and the number of *votes up* that it receives? Can we predict this value with a Machine Learning model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between the text of the review and the votes up\n",
    "\n",
    "We want to start with an easy model that just considers the text of the review and the votes up, in order to understand if there is a correlation between those two features. <br>\n",
    "If the overall accuracy of that simple model is good enough we'll stop and consider it as the optimal one, otherwise we'll add new reasonable features to the model in order to increase the obtained performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import reviews data from HDFS & select relevant features to perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "# Define the schema for the base reviews dataset\n",
    "base_reviews_schema = StructType([\n",
    "    StructField('base_review_id', LongType(), True),\n",
    "    StructField('steamid', LongType(), True),\n",
    "    StructField('appid', LongType(), True),\n",
    "    StructField('voted_up', BooleanType(), True),\n",
    "    StructField('votes_up', LongType(), True),\n",
    "    StructField('votes_funny', LongType(), True),\n",
    "    StructField('weighted_vote_score', DoubleType(), True),\n",
    "    StructField('playtime_forever', LongType(), True),\n",
    "    StructField('playtime_at_review', LongType(), True),\n",
    "    StructField('num_games_owned', LongType(), True),\n",
    "    StructField('num_reviews', LongType(), True),\n",
    "    StructField('review', StringType(), True),\n",
    "    StructField('unix_timestamp_created', LongType(), True),\n",
    "    StructField('unix_timestamp_updated', LongType(), True)\n",
    "])\n",
    "\n",
    "# Read the base reviews dataset from HDFS\n",
    "base_reviews_df = spark.read.csv(\n",
    "    path='hdfs://localhost:54310/final_project/data/base_reviews_filtered',\n",
    "    schema=base_reviews_schema,\n",
    "    escape='\"',\n",
    "    header=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    mode='FAILFAST',\n",
    "    multiLine=True,\n",
    "    unescapedQuoteHandling='STOP_AT_CLOSING_QUOTE'\n",
    ").to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>votes_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A masterpiece that is extremely underrated. Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not like 1 and 2 of the series but its alright.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unskippable cut scenes are horrible. Gameplay ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I enjoy the game.  Played it to 100% on PS3 an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feel the Payne ;)\\nGreat Game, just like part ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  votes_up\n",
       "0  A masterpiece that is extremely underrated. Th...         0\n",
       "1    Not like 1 and 2 of the series but its alright.         0\n",
       "2  Unskippable cut scenes are horrible. Gameplay ...         1\n",
       "3  I enjoy the game.  Played it to 100% on PS3 an...         0\n",
       "4  Feel the Payne ;)\\nGreat Game, just like part ...         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = base_reviews_df\n",
    "df[['review', 'votes_up']].to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide reviews in two classes: useful & not useful\n",
    "\n",
    "Since this hypothesis can be used by Steam in order to display, for users that are interested on buying a new game, only the potential useful reviews (the ones having more than N votes up) the idea is to consider only useful and not useful reviews and build a model that is capable of recognizing those two classes. <br>\n",
    "Since we do not want our model to be biased towards one of the two classes, we'll consider the same number of samples for the two different classes (useful/not useful review).<br>\n",
    "For us a good review is when its associated *votes_up* has a value greater than the M percentile of the overall *votes_up* distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes_up_for_useful_review = df.votes_up.quantile([.99])[0]\n",
    "votes_up_for_useful_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.pandas.set_option('compute.ops_on_diff_frames', True)\n",
    "useful_reviews_df = df[df['votes_up'] >= votes_up_for_useful_review]\n",
    "not_useful_reviews_df = df[df['votes_up'] < votes_up_for_useful_review].sample(frac=(useful_reviews_df.size/df.size), random_state=0)\n",
    "ps.pandas.reset_option('compute.ops_on_diff_frames')\n",
    "restricted_df = ps.pandas.concat([useful_reviews_df, not_useful_reviews_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Played ages ago and enjoyed it. Tried to play ...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[h1]Max Payne 3[/h1]\\n\\n[h1]\"I might have laug...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great game made by a shitty company which forc...</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it forces you to sign into rockstar social clu...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The captcha is broken and as I have to sign in...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  votes_up  useful\n",
       "0  Played ages ago and enjoyed it. Tried to play ...        34       1\n",
       "1  [h1]Max Payne 3[/h1]\\n\\n[h1]\"I might have laug...        40       1\n",
       "2  Great game made by a shitty company which forc...       185       1\n",
       "3  it forces you to sign into rockstar social clu...        41       1\n",
       "4  The captcha is broken and as I have to sign in...        36       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the output label with a 1 (so a good review) if the review's votes up are greater than threshold, 0 otherwise\n",
    "udf_y = udf(lambda x: 0 if x < votes_up_for_useful_review else 1, IntegerType())\n",
    "\n",
    "restricted_df = restricted_df.to_spark().withColumn('useful', udf_y(col('votes_up'))).to_pandas_on_spark()\n",
    "restricted_df[['review', 'votes_up', 'useful']].to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Bag-Of-Words and predict, using the review text, the votes_up categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark.ml works only with SQL Pyspark dataframes\n",
    "restricted_df = restricted_df.to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove not characters (and \\n) in written reviews and transform the text into lowercase\n",
    "def clean(input):\n",
    "    return ''.join(list(filter(lambda ele: re.search(\"[a-zA-Z\\s]+\", ele) is not None, list(re.sub('\\n', ' ', input.lower())))))\n",
    "\n",
    "udf_remove_not_characters = udf(lambda x: clean(x), StringType())\n",
    "clean_df = restricted_df.withColumn('cleaned_review', udf_remove_not_characters(col('review')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization - break review text into list of its individual terms (words in this case)\n",
    "tokenizer = Tokenizer(inputCol='cleaned_review', outputCol='review_words')\n",
    "wordsData = tokenizer.transform(clean_df)\n",
    "\n",
    "# Remove review having no words after filtering\n",
    "wordsData = wordsData.filter(size(col('review_words')) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing StopWords\n",
    "remover = StopWordsRemover(inputCol='review_words', outputCol='no_stop_words')\n",
    "filteredData = remover.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemmatization\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "udf_stemming = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "stemmed_df = filteredData.withColumn('stemmed_review', udf_stemming(col('no_stop_words')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>review_words</th>\n",
       "      <th>no_stop_words</th>\n",
       "      <th>stemmed_review</th>\n",
       "      <th>BoW</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Played ages ago and enjoyed it. Tried to play ...</td>\n",
       "      <td>played ages ago and enjoyed it tried to play a...</td>\n",
       "      <td>[played, ages, ago, and, enjoyed, it, tried, t...</td>\n",
       "      <td>[played, ages, ago, enjoyed, tried, play, coul...</td>\n",
       "      <td>[play, age, ago, enjoy, tri, play, couldnt, ge...</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, ...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[h1]Max Payne 3[/h1]\\n\\n[h1]\"I might have laug...</td>\n",
       "      <td>hmax payne h  hi might have laughed if i had r...</td>\n",
       "      <td>[hmax, payne, h, , hi, might, have, laughed, i...</td>\n",
       "      <td>[hmax, payne, h, , hi, might, laughed, remembe...</td>\n",
       "      <td>[hmax, payn, h, , hi, might, laugh, rememb, ho...</td>\n",
       "      <td>(58.0, 10.0, 13.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4....</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great game made by a shitty company which forc...</td>\n",
       "      <td>great game made by a shitty company which forc...</td>\n",
       "      <td>[great, game, made, by, a, shitty, company, wh...</td>\n",
       "      <td>[great, game, made, shitty, company, forces, m...</td>\n",
       "      <td>[great, game, made, shitti, compani, forc, mak...</td>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it forces you to sign into rockstar social clu...</td>\n",
       "      <td>it forces you to sign into rockstar social clu...</td>\n",
       "      <td>[it, forces, you, to, sign, into, rockstar, so...</td>\n",
       "      <td>[forces, sign, rockstar, social, club, single,...</td>\n",
       "      <td>[forc, sign, rockstar, social, club, singl, pl...</td>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The captcha is broken and as I have to sign in...</td>\n",
       "      <td>the captcha is broken and as i have to sign in...</td>\n",
       "      <td>[the, captcha, is, broken, and, as, i, have, t...</td>\n",
       "      <td>[captcha, broken, sign, play, cant, even, get,...</td>\n",
       "      <td>[captcha, broken, sign, play, cant, even, get,...</td>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  Played ages ago and enjoyed it. Tried to play ...   \n",
       "1  [h1]Max Payne 3[/h1]\\n\\n[h1]\"I might have laug...   \n",
       "2  Great game made by a shitty company which forc...   \n",
       "3  it forces you to sign into rockstar social clu...   \n",
       "4  The captcha is broken and as I have to sign in...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  played ages ago and enjoyed it tried to play a...   \n",
       "1  hmax payne h  hi might have laughed if i had r...   \n",
       "2  great game made by a shitty company which forc...   \n",
       "3  it forces you to sign into rockstar social clu...   \n",
       "4  the captcha is broken and as i have to sign in...   \n",
       "\n",
       "                                        review_words  \\\n",
       "0  [played, ages, ago, and, enjoyed, it, tried, t...   \n",
       "1  [hmax, payne, h, , hi, might, have, laughed, i...   \n",
       "2  [great, game, made, by, a, shitty, company, wh...   \n",
       "3  [it, forces, you, to, sign, into, rockstar, so...   \n",
       "4  [the, captcha, is, broken, and, as, i, have, t...   \n",
       "\n",
       "                                       no_stop_words  \\\n",
       "0  [played, ages, ago, enjoyed, tried, play, coul...   \n",
       "1  [hmax, payne, h, , hi, might, laughed, remembe...   \n",
       "2  [great, game, made, shitty, company, forces, m...   \n",
       "3  [forces, sign, rockstar, social, club, single,...   \n",
       "4  [captcha, broken, sign, play, cant, even, get,...   \n",
       "\n",
       "                                      stemmed_review  \\\n",
       "0  [play, age, ago, enjoy, tri, play, couldnt, ge...   \n",
       "1  [hmax, payn, h, , hi, might, laugh, rememb, ho...   \n",
       "2  [great, game, made, shitti, compani, forc, mak...   \n",
       "3  [forc, sign, rockstar, social, club, singl, pl...   \n",
       "4  [captcha, broken, sign, play, cant, even, get,...   \n",
       "\n",
       "                                                 BoW  votes_up  useful  \n",
       "0  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, ...        34       1  \n",
       "1  (58.0, 10.0, 13.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4....        40       1  \n",
       "2  (1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...       185       1  \n",
       "3  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...        41       1  \n",
       "4  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...        36       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply CountVectorizer - it converts the list of tokens to vector of token counts\n",
    "count = CountVectorizer(inputCol='no_stop_words', outputCol='BoW')\n",
    "model = count.fit(stemmed_df)\n",
    "featurizedData = model.transform(stemmed_df)\n",
    "featurizedData[['review', 'cleaned_review', 'review_words', 'no_stop_words', 'stemmed_review', 'BoW', 'votes_up', 'useful']].limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction using Logistic Regression (BoW)\n",
    "\n",
    "We'll start using an easier model and see the effects of using BoW on the overall performances. <br>\n",
    "In order to obtain a proper value for the regularization term of the Logistic Regression model a *grid search* approach has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoW</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(58.0, 10.0, 13.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BoW  useful\n",
       "0  (0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, ...       1\n",
       "1  (58.0, 10.0, 13.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4....       1\n",
       "2  (1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...       1\n",
       "3  (0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...       1\n",
       "4  (1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataframe in two - train & test\n",
    "projected_df = featurizedData[['BoW', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)\n",
    "projected_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 69.00\n",
      "Test Logistic Regression accuracy: 67.55\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(featuresCol='BoW', labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those results show (no matter the model) that there is a correlation between the text of the review and the *votes_up* label, otherwise the accuracy of our model would have been of the 50% (randomly picking one class). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new features to the simple model (that just uses reviews' text), to improve predictions \n",
    "\n",
    "Can we increase the accuracy of our model by adding new suited features to the model's input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather useful data about games and join them on 'appid' with reviews\n",
    "\n",
    "The review data are already stored, so we need to load the data about the games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>genres</th>\n",
       "      <th>owners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Action</td>\n",
       "      <td>10000000-20000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27070</th>\n",
       "      <td>1065160</td>\n",
       "      <td>Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27071</th>\n",
       "      <td>1065570</td>\n",
       "      <td>Action;Adventure;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27072</th>\n",
       "      <td>1066700</td>\n",
       "      <td>Adventure;Casual;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>1069460</td>\n",
       "      <td>Adventure;Casual;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27074</th>\n",
       "      <td>1065650</td>\n",
       "      <td>Action;Casual;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27075 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid                  genres             owners\n",
       "0           20                  Action   5000000-10000000\n",
       "1           30                  Action   5000000-10000000\n",
       "2           10                  Action  10000000-20000000\n",
       "3           50                  Action   5000000-10000000\n",
       "4           60                  Action   5000000-10000000\n",
       "...        ...                     ...                ...\n",
       "27070  1065160                   Indie            0-20000\n",
       "27071  1065570  Action;Adventure;Indie            0-20000\n",
       "27072  1066700  Adventure;Casual;Indie            0-20000\n",
       "27073  1069460  Adventure;Casual;Indie            0-20000\n",
       "27074  1065650     Action;Casual;Indie            0-20000\n",
       "\n",
       "[27075 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the mongo local and load as a dataframe the games collection\n",
    "mongo = pymongo.MongoClient()\n",
    "mongo_db = mongo.final_project\n",
    "games_df = pd.DataFrame(list(mongo_db.games.find({}, {'_id': False})))[['appid', 'genres', 'owners']]\n",
    "mongo.close() #Close the connections\n",
    "\n",
    "games_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better handling of game columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Genres\n",
    "\n",
    "Since a game can have at least one genre we'll store for each game a dict that has value equal to 1 if the genre applies to the game (0 otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df['genres'] = games_df.genres.str.split(';')\n",
    "# get all unique genres\n",
    "all_genres = games_df.genres.apply(pd.Series).stack().reset_index(drop=True).unique()\n",
    "# a dict for each game, each dict has all of the genres, val=1 if genre applies to game\n",
    "gen_dicts = games_df.genres.apply(lambda gens : { **{g:0 for g in all_genres}, **{ g:1 for g in gens } } )\n",
    "# delete now useless column\n",
    "del games_df['genres']\n",
    "# merge with original\n",
    "games_df = pd.concat([games_df.reset_index(drop=True), gen_dicts.apply(pd.Series).reset_index(drop=True)] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>owners</th>\n",
       "      <th>Action</th>\n",
       "      <th>Free to Play</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Indie</th>\n",
       "      <th>RPG</th>\n",
       "      <th>Animation &amp; Modeling</th>\n",
       "      <th>Video Production</th>\n",
       "      <th>...</th>\n",
       "      <th>Web Publishing</th>\n",
       "      <th>Education</th>\n",
       "      <th>Software Training</th>\n",
       "      <th>Sexual Content</th>\n",
       "      <th>Audio Production</th>\n",
       "      <th>Game Development</th>\n",
       "      <th>Photo Editing</th>\n",
       "      <th>Accounting</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10000000-20000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27070</th>\n",
       "      <td>1065160</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27071</th>\n",
       "      <td>1065570</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27072</th>\n",
       "      <td>1066700</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>1069460</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27074</th>\n",
       "      <td>1065650</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27075 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid             owners  Action  Free to Play  Strategy  Adventure  \\\n",
       "0           20   5000000-10000000       1             0         0          0   \n",
       "1           30   5000000-10000000       1             0         0          0   \n",
       "2           10  10000000-20000000       1             0         0          0   \n",
       "3           50   5000000-10000000       1             0         0          0   \n",
       "4           60   5000000-10000000       1             0         0          0   \n",
       "...        ...                ...     ...           ...       ...        ...   \n",
       "27070  1065160            0-20000       0             0         0          0   \n",
       "27071  1065570            0-20000       1             0         0          1   \n",
       "27072  1066700            0-20000       0             0         0          1   \n",
       "27073  1069460            0-20000       0             0         0          1   \n",
       "27074  1065650            0-20000       1             0         0          0   \n",
       "\n",
       "       Indie  RPG  Animation & Modeling  Video Production  ...  \\\n",
       "0          0    0                     0                 0  ...   \n",
       "1          0    0                     0                 0  ...   \n",
       "2          0    0                     0                 0  ...   \n",
       "3          0    0                     0                 0  ...   \n",
       "4          0    0                     0                 0  ...   \n",
       "...      ...  ...                   ...               ...  ...   \n",
       "27070      1    0                     0                 0  ...   \n",
       "27071      1    0                     0                 0  ...   \n",
       "27072      1    0                     0                 0  ...   \n",
       "27073      1    0                     0                 0  ...   \n",
       "27074      1    0                     0                 0  ...   \n",
       "\n",
       "       Web Publishing  Education  Software Training  Sexual Content  \\\n",
       "0                   0          0                  0               0   \n",
       "1                   0          0                  0               0   \n",
       "2                   0          0                  0               0   \n",
       "3                   0          0                  0               0   \n",
       "4                   0          0                  0               0   \n",
       "...               ...        ...                ...             ...   \n",
       "27070               0          0                  0               0   \n",
       "27071               0          0                  0               0   \n",
       "27072               0          0                  0               0   \n",
       "27073               0          0                  0               0   \n",
       "27074               0          0                  0               0   \n",
       "\n",
       "       Audio Production  Game Development  Photo Editing  Accounting  \\\n",
       "0                     0                 0              0           0   \n",
       "1                     0                 0              0           0   \n",
       "2                     0                 0              0           0   \n",
       "3                     0                 0              0           0   \n",
       "4                     0                 0              0           0   \n",
       "...                 ...               ...            ...         ...   \n",
       "27070                 0                 0              0           0   \n",
       "27071                 0                 0              0           0   \n",
       "27072                 0                 0              0           0   \n",
       "27073                 0                 0              0           0   \n",
       "27074                 0                 0              0           0   \n",
       "\n",
       "       Documentary  Tutorial  \n",
       "0                0         0  \n",
       "1                0         0  \n",
       "2                0         0  \n",
       "3                0         0  \n",
       "4                0         0  \n",
       "...            ...       ...  \n",
       "27070            0         0  \n",
       "27071            0         0  \n",
       "27072            0         0  \n",
       "27073            0         0  \n",
       "27074            0         0  \n",
       "\n",
       "[27075 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Owners\n",
    "\n",
    "Since we know for each game a range of the minimum and maximum number of owners, for each game we will consider the number of owners as a mean of those two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7500000\n",
       "1         7500000\n",
       "2        15000000\n",
       "3         7500000\n",
       "4         7500000\n",
       "           ...   \n",
       "27070       10000\n",
       "27071       10000\n",
       "27072       10000\n",
       "27073       10000\n",
       "27074       10000\n",
       "Name: owners, Length: 27075, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_owners_range = list(games_df.owners.str.split('-'))\n",
    "# Obtain the minimum and maximum values of owners for each videogame and cast those single values to Int\n",
    "list_min_games_owners = list(map(int, map(operator.itemgetter(0), games_owners_range)))\n",
    "list_max_games_owners = list(map(int, map(operator.itemgetter(-1), games_owners_range))) \n",
    "# For each game perform the mean value of owners\n",
    "games_df['owners'] = list(map(int, np.divide(list(map(operator.add, list_min_games_owners, list_max_games_owners)), 2)))\n",
    "games_df['owners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize game owners\n",
    "games_owners = np.array(games_df['owners'])[:, np.newaxis]\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(games_owners)\n",
    "games_df['owners_norm'] = scaler.transform(games_owners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_review_id</th>\n",
       "      <th>steamid</th>\n",
       "      <th>appid</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_at_review</th>\n",
       "      <th>num_games_owned</th>\n",
       "      <th>...</th>\n",
       "      <th>Education</th>\n",
       "      <th>Software Training</th>\n",
       "      <th>Sexual Content</th>\n",
       "      <th>Audio Production</th>\n",
       "      <th>Game Development</th>\n",
       "      <th>Photo Editing</th>\n",
       "      <th>Accounting</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Tutorial</th>\n",
       "      <th>owners_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133</td>\n",
       "      <td>76561198026373129</td>\n",
       "      <td>204100</td>\n",
       "      <td>False</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>0.663560</td>\n",
       "      <td>486</td>\n",
       "      <td>486</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.028497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>76561198154863069</td>\n",
       "      <td>204100</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.734658</td>\n",
       "      <td>1825</td>\n",
       "      <td>1825</td>\n",
       "      <td>233</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.028497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>76561198028004506</td>\n",
       "      <td>204100</td>\n",
       "      <td>False</td>\n",
       "      <td>185</td>\n",
       "      <td>21</td>\n",
       "      <td>0.794982</td>\n",
       "      <td>20598</td>\n",
       "      <td>20598</td>\n",
       "      <td>157</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.028497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234</td>\n",
       "      <td>76561198030245238</td>\n",
       "      <td>204100</td>\n",
       "      <td>False</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>0.658045</td>\n",
       "      <td>1259</td>\n",
       "      <td>1250</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.028497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>76561197976026546</td>\n",
       "      <td>204100</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0.676196</td>\n",
       "      <td>550</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.028497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   base_review_id            steamid   appid  voted_up  votes_up  votes_funny  \\\n",
       "0             133  76561198026373129  204100     False        34           18   \n",
       "1             224  76561198154863069  204100      True        40            1   \n",
       "2             226  76561198028004506  204100     False       185           21   \n",
       "3             234  76561198030245238  204100     False        41            3   \n",
       "4             306  76561197976026546  204100     False        36            6   \n",
       "\n",
       "   weighted_vote_score  playtime_forever  playtime_at_review  num_games_owned  \\\n",
       "0             0.663560               486                 486              300   \n",
       "1             0.734658              1825                1825              233   \n",
       "2             0.794982             20598               20598              157   \n",
       "3             0.658045              1259                1250               81   \n",
       "4             0.676196               550                  10               30   \n",
       "\n",
       "   ...  Education Software Training  Sexual Content  Audio Production  \\\n",
       "0  ...          0                 0               0                 0   \n",
       "1  ...          0                 0               0                 0   \n",
       "2  ...          0                 0               0                 0   \n",
       "3  ...          0                 0               0                 0   \n",
       "4  ...          0                 0               0                 0   \n",
       "\n",
       "   Game Development Photo Editing Accounting Documentary Tutorial owners_norm  \n",
       "0                 0             0          0           0        0    1.028497  \n",
       "1                 0             0          0           0        0    1.028497  \n",
       "2                 0             0          0           0        0    1.028497  \n",
       "3                 0             0          0           0        0    1.028497  \n",
       "4                 0             0          0           0        0    1.028497  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the subset of reviews and the games dataset \n",
    "games_df = spark.createDataFrame(games_df).to_pandas_on_spark()\n",
    "join_df = featurizedData.to_pandas_on_spark().merge(games_df, on='appid', how=\"left\")\n",
    "join_df.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add videogame owners (normalized), to the simple model (BoW)\n",
    "\n",
    "If the game is owned by lot of players maybe more user (e.g., that are interested on buying a community liked videogame) are reading the reviews and so more votes_up the review gets.<br>\n",
    "Applying a normalization to the videogame owners number is necessary since the range of values that this feature can have is larger with respect to the BoW (they can have more weight in the model and so the prediction results become unexpected). <br> A *Mean-Var Normalization* technique has been chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Pyspark ml wants a column as feature input we have to append to the BoW array also the game owners normalized\n",
    "vecAssembler = VectorAssembler(inputCols=['BoW', 'owners_norm'], outputCol='features')\n",
    "assembledData = vecAssembler.transform(join_df.to_spark())\n",
    "\n",
    "# Split the dataframe in two - train & test\n",
    "projected_df = assembledData[['features', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction using Logistic Regression (BoW + owners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 68.99\n",
      "Test Logistic Regression accuracy: 67.28\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that adding the owners really makes no visible improvements (with respect to the model having only the BoW as feature vector)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add videogame genre/s, to the simple model (BoW)\n",
    "\n",
    "From **hp3** we have obtained that some genres are more appreciated with respect to others, so maybe also the associated votes_up for a review is different if the review is referred to a game of a/some genre/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bow + genres\n",
    "cols = (list(join_df.columns[-32:-1]))\n",
    "del cols[-30]\n",
    "\n",
    "# Since Pyspark ml wants a column as feature input we have to append to the BoW array also the genres\n",
    "vecAssembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "assembledData = vecAssembler.transform(join_df.to_spark())\n",
    "\n",
    "# Split the dataframe in two - train & test\n",
    "projected_df = assembledData[['features', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction using Logistic Regression (BoW + genre/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 68.97\n",
      "Test Logistic Regression accuracy: 67.36\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that adding the owners really makes no visible improvements (with respect to the model having only the BoW as feature vector), a different result from what obtained with the local analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add how are liked the previous written reviews by a specific user, to the simple model (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possible consideration can be: if a person gets lots of likes in previous reviews maybe lots likes also the feature review gets.\n",
    "<br>\n",
    "The metric we are performing interested studying is:\n",
    " - **user_reviews_appreciation = sum_previous_reviews_votes_up / num_previous_reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy('steamid').orderBy('unix_timestamp_created').rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "join_df = join_df.to_spark().withColumn('user_reviews_appreciation', F.mean(col('votes_up')).over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "appreciation_mean = join_df.to_pandas_on_spark().user_reviews_appreciation.dropna().mean()\n",
    "\n",
    "# Replacing NaN values (user have written 0 previous reviews) with mean reviews likes value\n",
    "join_df = join_df.fillna(appreciation_mean, subset=['user_reviews_appreciation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform user_review_appreciation column as StandardScaler likes\n",
    "vecAssembler1 = VectorAssembler(inputCols=['user_reviews_appreciation'], outputCol='assembled_user_reviews_appreciation')\n",
    "assembledData = vecAssembler1.transform(join_df)\n",
    "\n",
    "# Normalize user reviews appreciation\n",
    "standardScaler = StandardScaler(inputCol='assembled_user_reviews_appreciation', outputCol='user_reviews_appreciation_norm')\n",
    "standardizedData = standardScaler.fit(assembledData).transform(assembledData)\n",
    "\n",
    "# Since Pyspark ml wants a column as feature input we have to append to the BoW array also the user_reviews_appreciation normalized\n",
    "vecAssembler = VectorAssembler(inputCols=['BoW', 'user_reviews_appreciation_norm'], outputCol='features')\n",
    "assembledData = vecAssembler.transform(standardizedData)\n",
    "\n",
    "# Split the dataframe in two - train & test\n",
    "projected_df = assembledData[['features', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (BoW + user_reviews_appreciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 69.06\n",
      "Test Logistic Regression accuracy: 66.08\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature slightly decreases the overall accuracy, so it cannot be considered as a good one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model - comparing all the considered features\n",
    "\n",
    "We noticed that adding features to the base model (the one considering only the BoW as feature) do not improve too much the overall accuracy (instead sometimes it slightly decreases).<br>\n",
    "It is better to not add features, as opposite as we have done in the local analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap - Logistic Regression (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 69.00\n",
      "Test Logistic Regression accuracy: 67.55\n"
     ]
    }
   ],
   "source": [
    "# Obtain useful data\n",
    "projected_df = featurizedData[['BoW', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)\n",
    "\n",
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(featuresCol='BoW', labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy of the obtained model can be considered neither good nor terrible.<br>\n",
    "It can be noticed that similar results, in terms of performances, have been obtained considering the local version, recalling that the distributed version works on lot more data.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other models\n",
    "\n",
    "What happens if we use instead different models such as Multinomial Naïve Bayes or SVM (using the same more relevant features)?<br><br>\n",
    "#### Multinomial Naïve Bayes (BoW)\n",
    "In order to obtain a proper value for the alpha hyperparameter (smoothing) of the Multinomial Naïve Bayes model a grid search approach has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Multinomial Naive Bayes accuracy: 73.43\n",
      "Test Multinomial Naive Bayes accuracy: 70.07\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of Multinomial Naive Bayes classifier\n",
    "mnb = NaiveBayes(modelType='multinomial', featuresCol='BoW', labelCol='useful', smoothing=1.9)\n",
    "\n",
    "# Fit the model\n",
    "mnb_model = mnb.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='useful', metricName='accuracy') \n",
    "print(f\"Train Multinomial Naive Bayes accuracy: {(evaluator.evaluate(mnb_model.transform(trainDF))) * 100:.2f}\")\n",
    "print(f\"Test Multinomial Naive Bayes accuracy: {(evaluator.evaluate(mnb_model.transform(testDF))) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naïve Bayes model does not improve overall accuracy with respect to the Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Support Vector Machine (BoW)\n",
    "\n",
    "Unfortunately Pyspark does not implement SVM using not linear kernels, so we opted for the linear version hoping it will work better with respect to Logistic regression. <br>\n",
    "In order to obtain a proper value for the regularization term of the SVM model a *grid search* approach has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Linear SVM accuracy: 66.17\n",
      "Test Linear SVM accuracy: 63.14\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of linear SVM classifier\n",
    "l_svm = LinearSVC(featuresCol='BoW', labelCol='useful', regParam=10)\n",
    "\n",
    "# Fit the model\n",
    "l_svm_model = l_svm.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Linear SVM accuracy: {(l_svm_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Linear SVM accuracy: {(l_svm_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM model does not improve the overall accuracy with respect to the Logistic Regression, furthermore it takes lot more time for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation - using the \"best model\"\n",
    "\n",
    "Is our \"best model\" more biased towards recognizing one of the two classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_acc = lr_model.evaluate(testDF).accuracy\n",
    "l_svm_acc = l_svm_model.evaluate(testDF).accuracy\n",
    "# mnb_acc = evaluator.evaluate(mnb_model.transform(testDF))\n",
    "\n",
    "acc_list = [lr_acc, l_svm_acc]\n",
    "models = [lr_model, l_svm_model]\n",
    "best_model = models[acc_list.index(max(acc_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = best_model.transform(testDF)\n",
    "predictions = (predictions.withColumn('label', predictions['useful'].cast('double')))\n",
    "metrics = MulticlassMetrics(predictions.select(['label', 'prediction']).rdd)\n",
    "\n",
    "cf_matrix = metrics.confusionMatrix().toArray()\n",
    "sb.heatmap(cf_matrix/np.sum(cf_matrix),\n",
    "           annot=True,\n",
    "           fmt='.1%',\n",
    "           cmap='Blues',\n",
    "           cbar=False,\n",
    "           xticklabels=['False', 'True'], yticklabels=['False', 'True'],\n",
    "           annot_kws={\n",
    "                'fontsize': 14\n",
    "            }).set(xlabel='Predicted class', ylabel='Actual class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: LogisticRegressionModel \n",
      "\n",
      "Precision: 0.68 \n",
      "Recall: 0.53 \n",
      "F1: 0.66\n",
      "\n",
      "Area under Precision-Recall curve:  0.74\n"
     ]
    }
   ],
   "source": [
    "precision = (metrics.precision(0.0) + metrics.precision(1.0)) / 2\n",
    "recall = (metrics.recall(0.0) + metrics.precision(1.0)) / 2\n",
    "f1 = (metrics.fMeasure(0.0) + metrics.fMeasure(1.0)) / 2\n",
    "print('Best model:', str(type(best_model).__name__),\n",
    "     '\\n\\nPrecision:', round(precision, 2), '\\nRecall:', round(recall, 2), '\\nF1:', round(f1,2))\n",
    "area_under_PR = BinaryClassificationMetrics(predictions.select(['prediction', 'label']).rdd).areaUnderPR\n",
    "print('\\nArea under Precision-Recall curve: ', round(area_under_PR , 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark context underlying the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
