{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spark located in /usr/local/spark/.\n"
     ]
    }
   ],
   "source": [
    "import findspark, sys\n",
    "\n",
    "# Locate the Spark installation (add pyspark to sys.path, see https://github.com/minrk/findspark#readme)\n",
    "findspark.init()\n",
    "print(f'Using Spark located in {findspark.find()}.')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create or get the Spark session (singleton) and the underlying Spark context\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps, nltk, pymongo, pandas as pd, re, sklearn, operator, numpy as np, seaborn as sb\n",
    "from pyspark.sql.functions import udf, col, size\n",
    "from pyspark.sql.types import BooleanType, DoubleType, LongType, StringType, StructField, StructType, IntegerType, ArrayType\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer, StopWordsRemover, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, LinearSVC\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "\n",
    "from pyspark.sql import functions as F, Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fifth Hypothesis:\n",
    "\n",
    "In the following notebook the following hypothesis, already analyzed in local (using standard python), will be replicated on the Big Data source located in the HDFS:\n",
    " - **Does there exist a relationship between the text of the review and the number of *votes up* that it receives? Can we predict this value with a Machine Learning model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between the text of the review and the votes up\n",
    "\n",
    "We want to start with an easy model that just considers the text of the review and the votes up, in order to understand if there is a correlation between those two features. <br>\n",
    "If the overall accuracy of that simple model is good enough we'll stop considering it as the optimal one, otherwise we'll add new reasonable features to the model in order to increase the obtained performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import reviews data from HDFS & select relevant features to perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the base reviews dataset\n",
    "base_reviews_schema = StructType([\n",
    "    #StructField('base_review_id', LongType(), True),\n",
    "    StructField('steamid', LongType(), True),\n",
    "    StructField('appid', LongType(), True),\n",
    "    StructField('voted_up', BooleanType(), True),\n",
    "    StructField('votes_up', LongType(), True),\n",
    "    StructField('votes_funny', LongType(), True),\n",
    "    StructField('weighted_vote_score', DoubleType(), True),\n",
    "    StructField('playtime_forever', LongType(), True),\n",
    "    StructField('playtime_at_review', LongType(), True),\n",
    "    StructField('num_games_owned', LongType(), True),\n",
    "    StructField('num_reviews', LongType(), True),\n",
    "    StructField('review', StringType(), True),\n",
    "    StructField('unix_timestamp_created', LongType(), True),\n",
    "    StructField('unix_timestamp_updated', LongType(), True)\n",
    "])\n",
    "\n",
    "# Read the base reviews dataset from HDFS\n",
    "base_reviews_df = spark.read.csv(\n",
    "    path='hdfs://localhost:54310/final_project/data/base_reviews',\n",
    "    schema=base_reviews_schema,\n",
    "    escape='\"',\n",
    "    header=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    mode='FAILFAST',\n",
    "    multiLine=True,\n",
    "    unescapedQuoteHandling='STOP_AT_CLOSING_QUOTE'\n",
    ").to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>votes_up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best gameplay ever created</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Timeless. Thank you volvo.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this game literally made me love guns and fps ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If this gets a rework in 2021 it's going to be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  votes_up\n",
       "0                         best gameplay ever created         0\n",
       "1                         Timeless. Thank you volvo.         0\n",
       "2  this game literally made me love guns and fps ...         0\n",
       "3  If this gets a rework in 2021 it's going to be...         0\n",
       "4                                                 ok         0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = base_reviews_df\n",
    "df[['review', 'votes_up']].to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty text reviews\n",
    "\n",
    "We saw in the local analysis that some reviews have an associated empty text, even in this case we'll remove those reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed reviews: 24271\n"
     ]
    }
   ],
   "source": [
    "tot_len = df.size\n",
    "# Remove NaN elements in dataframe\n",
    "df = df.dropna(subset=\"review\")\n",
    "print(f\"Removed reviews: {tot_len - df.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide reviews in two classes: useful & not useful\n",
    "\n",
    "Since this hypothesis can be used by Steam in order to display, for users that are interested on buying a new game, only the potential useful reviews (the ones having more than N votes up) the idea is to consider only useful and not useful reviews and build a model that is capable of recognizing those two classes. <br>\n",
    "Since we do not want our model to be biased towards one of the two classes, we'll consider the same number of samples for the two different classes (useful/not useful review).<br>\n",
    "For us a good review is when its associated *votes_up* has a value greater than the M percentile of the overall *votes_up* distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes_up_for_useful_review = df.votes_up.quantile([.99])[0]\n",
    "votes_up_for_useful_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.pandas.set_option('compute.ops_on_diff_frames', True)\n",
    "useful_reviews_df = df[df['votes_up'] >= votes_up_for_useful_review]\n",
    "not_useful_reviews_df = df[df['votes_up'] < votes_up_for_useful_review].sample(frac=(useful_reviews_df.size/df.size), random_state=0)\n",
    "ps.pandas.reset_option('compute.ops_on_diff_frames')\n",
    "# NOTE: Unfortunately the len of the two dataframes is not equal\n",
    "restricted_df = ps.pandas.concat([useful_reviews_df, not_useful_reviews_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣠⣤⣤⣄⣀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\\n⠀⠀⠀⠀...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GAME OF MY CHILDHOOD\\nRECCOMEND IT \\nLEGENT NE...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legendary game, watched my uncle play it a lot...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the best games ever made and still aliv...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Were we all started..</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  votes_up  useful\n",
       "0  ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣠⣤⣤⣄⣀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\\n⠀⠀⠀⠀...        16       1\n",
       "1  GAME OF MY CHILDHOOD\\nRECCOMEND IT \\nLEGENT NE...        11       1\n",
       "2  Legendary game, watched my uncle play it a lot...        34       1\n",
       "3  One of the best games ever made and still aliv...        13       1\n",
       "4                              Were we all started..        26       1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the output label with a 1 (so a good review) if the review's votes up are greater than threshold, 0 otherwise\n",
    "udf_y = udf(lambda x: 0 if x < votes_up_for_useful_review else 1, IntegerType())\n",
    "\n",
    "restricted_df = restricted_df.to_spark().withColumn('useful', udf_y(col('votes_up'))).to_pandas_on_spark()\n",
    "restricted_df[['review', 'votes_up', 'useful']].to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Bag-Of-Words and predict, using the review text, the votes_up categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark.ml works only with SQL Pyspark dataframes\n",
    "restricted_df = restricted_df.to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove not characters (and \\n) in written reviews and transform the text into lowercase\n",
    "def clean(input):\n",
    "    return ''.join(list(filter(lambda ele: re.search(\"[a-zA-Z\\s]+\", ele) is not None, list(re.sub('\\n', ' ', input.lower())))))\n",
    "\n",
    "udf_remove_not_characters = udf(lambda x: clean(x), StringType())\n",
    "clean_df = restricted_df.withColumn('cleaned_review', udf_remove_not_characters(col('review')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization - break review text into list of its individual terms (words in this case)\n",
    "tokenizer = Tokenizer(inputCol='cleaned_review', outputCol='review_words')\n",
    "wordsData = tokenizer.transform(clean_df)\n",
    "\n",
    "# Remove review having no words after filtering\n",
    "wordsData = wordsData.filter(size(col('review_words')) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing StopWords\n",
    "remover = StopWordsRemover(inputCol='review_words', outputCol='no_stop_words')\n",
    "filteredData = remover.transform(wordsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemmatization\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "udf_stemming = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "stemmed_df = filteredData.withColumn('stemmed_review', udf_stemming(col('no_stop_words')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>review_words</th>\n",
       "      <th>no_stop_words</th>\n",
       "      <th>stemmed_review</th>\n",
       "      <th>BoW</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAME OF MY CHILDHOOD\\nRECCOMEND IT \\nLEGENT NE...</td>\n",
       "      <td>game of my childhood reccomend it  legent neve...</td>\n",
       "      <td>[game, of, my, childhood, reccomend, it, , leg...</td>\n",
       "      <td>[game, childhood, reccomend, , legent, never, ...</td>\n",
       "      <td>[game, childhood, reccomend, , legent, never, ...</td>\n",
       "      <td>(1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Legendary game, watched my uncle play it a lot...</td>\n",
       "      <td>legendary game watched my uncle play it a lot ...</td>\n",
       "      <td>[legendary, game, watched, my, uncle, play, it...</td>\n",
       "      <td>[legendary, game, watched, uncle, play, lot, i...</td>\n",
       "      <td>[legendari, game, watch, uncl, play, lot, inhe...</td>\n",
       "      <td>(0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One of the best games ever made and still aliv...</td>\n",
       "      <td>one of the best games ever made and still aliv...</td>\n",
       "      <td>[one, of, the, best, games, ever, made, and, s...</td>\n",
       "      <td>[one, best, games, ever, made, still, alive, t...</td>\n",
       "      <td>[one, best, game, ever, made, still, aliv, today]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Were we all started..</td>\n",
       "      <td>were we all started</td>\n",
       "      <td>[were, we, all, started]</td>\n",
       "      <td>[started]</td>\n",
       "      <td>[start]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I wish I grew up playing this, not global offe...</td>\n",
       "      <td>i wish i grew up playing this not global offen...</td>\n",
       "      <td>[i, wish, i, grew, up, playing, this, not, glo...</td>\n",
       "      <td>[wish, grew, playing, global, offensive]</td>\n",
       "      <td>[wish, grew, play, global, offens]</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  GAME OF MY CHILDHOOD\\nRECCOMEND IT \\nLEGENT NE...   \n",
       "1  Legendary game, watched my uncle play it a lot...   \n",
       "2  One of the best games ever made and still aliv...   \n",
       "3                              Were we all started..   \n",
       "4  I wish I grew up playing this, not global offe...   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  game of my childhood reccomend it  legent neve...   \n",
       "1  legendary game watched my uncle play it a lot ...   \n",
       "2  one of the best games ever made and still aliv...   \n",
       "3                                were we all started   \n",
       "4  i wish i grew up playing this not global offen...   \n",
       "\n",
       "                                        review_words  \\\n",
       "0  [game, of, my, childhood, reccomend, it, , leg...   \n",
       "1  [legendary, game, watched, my, uncle, play, it...   \n",
       "2  [one, of, the, best, games, ever, made, and, s...   \n",
       "3                           [were, we, all, started]   \n",
       "4  [i, wish, i, grew, up, playing, this, not, glo...   \n",
       "\n",
       "                                       no_stop_words  \\\n",
       "0  [game, childhood, reccomend, , legent, never, ...   \n",
       "1  [legendary, game, watched, uncle, play, lot, i...   \n",
       "2  [one, best, games, ever, made, still, alive, t...   \n",
       "3                                          [started]   \n",
       "4           [wish, grew, playing, global, offensive]   \n",
       "\n",
       "                                      stemmed_review  \\\n",
       "0  [game, childhood, reccomend, , legent, never, ...   \n",
       "1  [legendari, game, watch, uncl, play, lot, inhe...   \n",
       "2  [one, best, game, ever, made, still, aliv, today]   \n",
       "3                                            [start]   \n",
       "4                 [wish, grew, play, global, offens]   \n",
       "\n",
       "                                                 BoW  votes_up  useful  \n",
       "0  (1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        11       1  \n",
       "1  (0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, ...        34       1  \n",
       "2  (0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...        13       1  \n",
       "3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        26       1  \n",
       "4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        12       1  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply CountVectorizer - it converts the list of tokens to vector of token counts\n",
    "count = CountVectorizer(inputCol='no_stop_words', outputCol='BoW')\n",
    "model = count.fit(stemmed_df)\n",
    "featurizedData = model.transform(stemmed_df)\n",
    "featurizedData[['review', 'cleaned_review', 'review_words', 'no_stop_words', 'stemmed_review', 'BoW', 'votes_up', 'useful']].limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction using Logistic Regression (BoW)\n",
    "\n",
    "We'll start using an easier model and see the effects of using BoW on the overall performances. <br>\n",
    "In order to obtain a proper value for the regularization term of the Logistic Regression model a *grid search* approach has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe in two - train & test\n",
    "projected_df = featurizedData[['BoW', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)\n",
    "projected_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 67.40\n",
      "Test Logistic Regression accuracy: 64.29\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(featuresCol='BoW', labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those results show (no matter the model) that there is a correlation between the text of the review and the *votes_up* label, otherwise the accuracy of our model would have been of the 50% (randomly picking one class). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new features to the simple model (that just uses reviews' text), to improve predictions \n",
    "\n",
    "Can we increase the accuracy of our model by adding new suited features to the model's input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather useful data about games and join them on 'appid' with reviews\n",
    "\n",
    "The review data are already stored, so we need to load the data about the games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>genres</th>\n",
       "      <th>owners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Action</td>\n",
       "      <td>10000000-20000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Action</td>\n",
       "      <td>5000000-10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27070</th>\n",
       "      <td>1065230</td>\n",
       "      <td>Adventure;Casual;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27071</th>\n",
       "      <td>1065570</td>\n",
       "      <td>Action;Adventure;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27072</th>\n",
       "      <td>1065650</td>\n",
       "      <td>Action;Casual;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>1066700</td>\n",
       "      <td>Adventure;Casual;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27074</th>\n",
       "      <td>1069460</td>\n",
       "      <td>Adventure;Casual;Indie</td>\n",
       "      <td>0-20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27075 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid                  genres             owners\n",
       "0           10                  Action  10000000-20000000\n",
       "1           20                  Action   5000000-10000000\n",
       "2           30                  Action   5000000-10000000\n",
       "3           40                  Action   5000000-10000000\n",
       "4           50                  Action   5000000-10000000\n",
       "...        ...                     ...                ...\n",
       "27070  1065230  Adventure;Casual;Indie            0-20000\n",
       "27071  1065570  Action;Adventure;Indie            0-20000\n",
       "27072  1065650     Action;Casual;Indie            0-20000\n",
       "27073  1066700  Adventure;Casual;Indie            0-20000\n",
       "27074  1069460  Adventure;Casual;Indie            0-20000\n",
       "\n",
       "[27075 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the mongo local and load as a dataframe the games collection\n",
    "mongo = pymongo.MongoClient()\n",
    "mongo_db = mongo.final_project\n",
    "games_df = pd.DataFrame(list(mongo_db.games.find({}, {'_id': False})))[['appid', 'genres', 'owners']]\n",
    "mongo.close() #Close the connections\n",
    "\n",
    "games_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Better handling of game columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Genres\n",
    "\n",
    "Since a game can have at least one genre we'll store for each game a dict that has value equal to 1 if the genre applies to the game (0 otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df['genres'] = games_df.genres.str.split(';')\n",
    "# get all unique genres\n",
    "all_genres = games_df.genres.apply(pd.Series).stack().reset_index(drop=True).unique()\n",
    "# a dict for each game, each dict has all of the genres, val=1 if genre applies to game\n",
    "gen_dicts = games_df.genres.apply(lambda gens : { **{g:0 for g in all_genres}, **{ g:1 for g in gens } } )\n",
    "# delete now useless column\n",
    "del games_df['genres']\n",
    "# merge with original\n",
    "games_df = pd.concat([games_df.reset_index(drop=True), gen_dicts.apply(pd.Series).reset_index(drop=True)] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>owners</th>\n",
       "      <th>Action</th>\n",
       "      <th>Free to Play</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Indie</th>\n",
       "      <th>RPG</th>\n",
       "      <th>Animation &amp; Modeling</th>\n",
       "      <th>Video Production</th>\n",
       "      <th>...</th>\n",
       "      <th>Web Publishing</th>\n",
       "      <th>Education</th>\n",
       "      <th>Software Training</th>\n",
       "      <th>Sexual Content</th>\n",
       "      <th>Audio Production</th>\n",
       "      <th>Game Development</th>\n",
       "      <th>Photo Editing</th>\n",
       "      <th>Accounting</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Tutorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10000000-20000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>5000000-10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27070</th>\n",
       "      <td>1065230</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27071</th>\n",
       "      <td>1065570</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27072</th>\n",
       "      <td>1065650</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>1066700</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27074</th>\n",
       "      <td>1069460</td>\n",
       "      <td>0-20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27075 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appid             owners  Action  Free to Play  Strategy  Adventure  \\\n",
       "0           10  10000000-20000000       1             0         0          0   \n",
       "1           20   5000000-10000000       1             0         0          0   \n",
       "2           30   5000000-10000000       1             0         0          0   \n",
       "3           40   5000000-10000000       1             0         0          0   \n",
       "4           50   5000000-10000000       1             0         0          0   \n",
       "...        ...                ...     ...           ...       ...        ...   \n",
       "27070  1065230            0-20000       0             0         0          1   \n",
       "27071  1065570            0-20000       1             0         0          1   \n",
       "27072  1065650            0-20000       1             0         0          0   \n",
       "27073  1066700            0-20000       0             0         0          1   \n",
       "27074  1069460            0-20000       0             0         0          1   \n",
       "\n",
       "       Indie  RPG  Animation & Modeling  Video Production  ...  \\\n",
       "0          0    0                     0                 0  ...   \n",
       "1          0    0                     0                 0  ...   \n",
       "2          0    0                     0                 0  ...   \n",
       "3          0    0                     0                 0  ...   \n",
       "4          0    0                     0                 0  ...   \n",
       "...      ...  ...                   ...               ...  ...   \n",
       "27070      1    0                     0                 0  ...   \n",
       "27071      1    0                     0                 0  ...   \n",
       "27072      1    0                     0                 0  ...   \n",
       "27073      1    0                     0                 0  ...   \n",
       "27074      1    0                     0                 0  ...   \n",
       "\n",
       "       Web Publishing  Education  Software Training  Sexual Content  \\\n",
       "0                   0          0                  0               0   \n",
       "1                   0          0                  0               0   \n",
       "2                   0          0                  0               0   \n",
       "3                   0          0                  0               0   \n",
       "4                   0          0                  0               0   \n",
       "...               ...        ...                ...             ...   \n",
       "27070               0          0                  0               0   \n",
       "27071               0          0                  0               0   \n",
       "27072               0          0                  0               0   \n",
       "27073               0          0                  0               0   \n",
       "27074               0          0                  0               0   \n",
       "\n",
       "       Audio Production  Game Development  Photo Editing  Accounting  \\\n",
       "0                     0                 0              0           0   \n",
       "1                     0                 0              0           0   \n",
       "2                     0                 0              0           0   \n",
       "3                     0                 0              0           0   \n",
       "4                     0                 0              0           0   \n",
       "...                 ...               ...            ...         ...   \n",
       "27070                 0                 0              0           0   \n",
       "27071                 0                 0              0           0   \n",
       "27072                 0                 0              0           0   \n",
       "27073                 0                 0              0           0   \n",
       "27074                 0                 0              0           0   \n",
       "\n",
       "       Documentary  Tutorial  \n",
       "0                0         0  \n",
       "1                0         0  \n",
       "2                0         0  \n",
       "3                0         0  \n",
       "4                0         0  \n",
       "...            ...       ...  \n",
       "27070            0         0  \n",
       "27071            0         0  \n",
       "27072            0         0  \n",
       "27073            0         0  \n",
       "27074            0         0  \n",
       "\n",
       "[27075 rows x 31 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Owners\n",
    "\n",
    "Since we know for each game a range of the minimum and maximum number of owners, for each game we will consider the number of owners as a mean of those two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        15000000\n",
       "1         7500000\n",
       "2         7500000\n",
       "3         7500000\n",
       "4         7500000\n",
       "           ...   \n",
       "27070       10000\n",
       "27071       10000\n",
       "27072       10000\n",
       "27073       10000\n",
       "27074       10000\n",
       "Name: owners, Length: 27075, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_owners_range = list(games_df.owners.str.split('-'))\n",
    "# Obtain the minimum and maximum values of owners for each videogame and cast those single values to Int\n",
    "list_min_games_owners = list(map(int, map(operator.itemgetter(0), games_owners_range)))\n",
    "list_max_games_owners = list(map(int, map(operator.itemgetter(-1), games_owners_range))) \n",
    "# For each game perform the mean value of owners\n",
    "games_df['owners'] = list(map(int, np.divide(list(map(operator.add, list_min_games_owners, list_max_games_owners)), 2)))\n",
    "games_df['owners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize game owners\n",
    "games_owners = np.array(games_df['owners'])[:, np.newaxis]\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(games_owners)\n",
    "games_df['owners_norm'] = scaler.transform(games_owners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steamid</th>\n",
       "      <th>appid</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>votes_up</th>\n",
       "      <th>votes_funny</th>\n",
       "      <th>weighted_vote_score</th>\n",
       "      <th>playtime_forever</th>\n",
       "      <th>playtime_at_review</th>\n",
       "      <th>num_games_owned</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>Education</th>\n",
       "      <th>Software Training</th>\n",
       "      <th>Sexual Content</th>\n",
       "      <th>Audio Production</th>\n",
       "      <th>Game Development</th>\n",
       "      <th>Photo Editing</th>\n",
       "      <th>Accounting</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Tutorial</th>\n",
       "      <th>owners_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198989429229</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0.629035</td>\n",
       "      <td>348</td>\n",
       "      <td>348</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.193669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561198053333797</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.772390</td>\n",
       "      <td>111772</td>\n",
       "      <td>111760</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.193669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561198009260426</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.645567</td>\n",
       "      <td>5893</td>\n",
       "      <td>5819</td>\n",
       "      <td>278</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.193669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198149805308</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.721466</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.193669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198358607702</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.659487</td>\n",
       "      <td>10975</td>\n",
       "      <td>1097</td>\n",
       "      <td>526</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.193669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             steamid  appid  voted_up  votes_up  votes_funny  \\\n",
       "0  76561198989429229     10      True        11            6   \n",
       "1  76561198053333797     10      True        34            2   \n",
       "2  76561198009260426     10      True        13            1   \n",
       "3  76561198149805308     10      True        26            2   \n",
       "4  76561198358607702     10      True        12            1   \n",
       "\n",
       "   weighted_vote_score  playtime_forever  playtime_at_review  num_games_owned  \\\n",
       "0             0.629035               348                 348                4   \n",
       "1             0.772390            111772              111760               28   \n",
       "2             0.645567              5893                5819              278   \n",
       "3             0.721466               124                 124               26   \n",
       "4             0.659487             10975                1097              526   \n",
       "\n",
       "   num_reviews  ... Education  Software Training  Sexual Content  \\\n",
       "0            4  ...         0                  0               0   \n",
       "1            2  ...         0                  0               0   \n",
       "2           36  ...         0                  0               0   \n",
       "3            7  ...         0                  0               0   \n",
       "4          227  ...         0                  0               0   \n",
       "\n",
       "   Audio Production Game Development Photo Editing Accounting Documentary  \\\n",
       "0                 0                0             0          0           0   \n",
       "1                 0                0             0          0           0   \n",
       "2                 0                0             0          0           0   \n",
       "3                 0                0             0          0           0   \n",
       "4                 0                0             0          0           0   \n",
       "\n",
       "  Tutorial  owners_norm  \n",
       "0        0    11.193669  \n",
       "1        0    11.193669  \n",
       "2        0    11.193669  \n",
       "3        0    11.193669  \n",
       "4        0    11.193669  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the subset of reviews and the games dataset \n",
    "games_df = spark.createDataFrame(games_df).to_pandas_on_spark()\n",
    "join_df = featurizedData.to_pandas_on_spark().merge(games_df, on='appid', how=\"left\")\n",
    "join_df.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add videogame owners (normalized), to the simple model (BoW)\n",
    "\n",
    "If the game is owned by lot of players maybe more user (e.g., that are interested on buying a community liked videogame) are reading the reviews and so more votes_up the review gets.<br>\n",
    "Applying a normalization to the videogame owners number is necessary since the range of values that this feature can have is larger with respect to the BoW (they can have more weight in the model and so the prediction results become unexpected). <br> A *Mean-Var Normalization* technique has been chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Pyspark ml wants a column as feature input we have to append to the BoW array also the game owners normalized\n",
    "vecAssembler = VectorAssembler(inputCols=['BoW', 'owners_norm'], outputCol='features')\n",
    "assembledData = vecAssembler.transform(join_df.to_spark())\n",
    "\n",
    "# Split the dataframe in two - train & test\n",
    "projected_df = assembledData[['features', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction using Logistic Regression (BoW + owners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 67.94\n",
      "Test Logistic Regression accuracy: 64.94\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be noticed that a slightly improvement is added if considering also the number of players that own that particular game. <br>\n",
    "This suggest to add this feature to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add videogame genre/s, to the simple model (BoW)\n",
    "\n",
    "From **hp3** we have obtained that some genres are more appreciated with respect to others, so maybe also the associated votes_up for a review is different if the review is referred to a game of a/some genre/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bow + genres\n",
    "cols = (list(join_df.columns[-32:-1]))\n",
    "del cols[-30]\n",
    "\n",
    "# Since Pyspark ml wants a column as feature input we have to append to the BoW array also the genres\n",
    "vecAssembler = VectorAssembler(inputCols=cols, outputCol='features')\n",
    "assembledData = vecAssembler.transform(join_df.to_spark())\n",
    "\n",
    "# Split the dataframe in two - train & test\n",
    "projected_df = assembledData[['features', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction using Logistic Regression (BoW + genre/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 68.16\n",
      "Test Logistic Regression accuracy: 65.24\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that adding the genre/s to the model produces overfitting (the training accuracy increases whereas the test decreases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add how are liked the review written by a specific user, to the simple model (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possible consideration can be: if a person gets lots of likes in previous reviews maybe lots likes also the feature review gets.\n",
    "<br>\n",
    "The metric we are performing interested studying is:\n",
    " - **user_reviews_appreciation = sum_previous_reviews_votes_up / num_previous_reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy('steamid').orderBy('unix_timestamp_created').rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "join_df = join_df.to_spark().withColumn('user_reviews_appreciation', F.mean(col('votes_up')).over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "appreciation_mean = join_df.to_pandas_on_spark().user_reviews_appreciation.dropna().mean()\n",
    "\n",
    "# Replacing NaN values (user have written 0 previous reviews) with mean reviews likes value\n",
    "join_df = join_df.fillna(appreciation_mean, subset=['user_reviews_appreciation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform user_review_appreciation column as StandardScaler likes\n",
    "vecAssembler1 = VectorAssembler(inputCols=['user_reviews_appreciation'], outputCol='assembled_user_reviews_appreciation')\n",
    "assembledData = vecAssembler1.transform(join_df)\n",
    "\n",
    "# Normalize user reviews appreciation\n",
    "standardScaler = StandardScaler(inputCol='assembled_user_reviews_appreciation', outputCol='user_reviews_appreciation_norm')\n",
    "standardizedData = standardScaler.fit(assembledData).transform(assembledData)\n",
    "\n",
    "# Since Pyspark ml wants a column as feature input we have to append to the BoW array also the user_reviews_appreciation normalized\n",
    "vecAssembler = VectorAssembler(inputCols=['BoW', 'user_reviews_appreciation_norm'], outputCol='features')\n",
    "assembledData = vecAssembler.transform(standardizedData)\n",
    "\n",
    "# Split the dataframe in two - train & test\n",
    "projected_df = assembledData[['features', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (BoW + user_reviews_appreciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 68.00\n",
      "Test Logistic Regression accuracy: 65.07\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature improves a lot the overall accuracy, so it can be considered as a good one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model (using all the more relevant features)\n",
    "\n",
    "Since we noticed that adding some features increases more with respect to other the overall accuracy is better to add only the more relevant features (the ones that are changing most the accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Pyspark ml wants a column as feature input we have to append to the BoW array also the user_reviews_appreciation normalized\n",
    "vecAssembler = VectorAssembler(inputCols=['BoW', 'owners_norm', 'user_reviews_appreciation_norm'], outputCol='features')\n",
    "assembledData = vecAssembler.transform(standardizedData)\n",
    "\n",
    "# Split the dataframe in two - train & test\n",
    "projected_df = assembledData[['features', 'useful']]\n",
    "trainDF, testDF = projected_df.randomSplit([0.9, 0.1], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression (BoW + owners + user_reviews_appreciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 68.00\n",
      "Test Logistic Regression accuracy: 65.07\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of LogisticRegression classifier\n",
    "lr = LogisticRegression(labelCol='useful', regParam=30)\n",
    "\n",
    "# Fit the model\n",
    "lr_model = lr.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(lr_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(lr_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall accuracy can be considered not as optimal, but good enough (for sure better than the simpler model, the one that only uses BoW).<br>\n",
    "Remember that we use not a huge number of features, and the training using simple models (like Logistic Regression) takes fewer time. <br><br>\n",
    "During this discussion we only used the Logistic Regression, but what happens if we use instead different models such as SVM (using the more relevant features)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Support Vector Machine (BoW + owners + user_review_appreciation)\n",
    "\n",
    "Unfortunately Pyspark does not implement SVM using not linear kernels, so we opted for the linear version hoping it will work better with respect to Logistic regression.\n",
    "In order to obtain a proper value for the regularization term of the SVM model a *grid search* approach has been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Logistic Regression accuracy: 61.61\n",
      "Test Logistic Regression accuracy: 58.24\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of linear SVM classifier\n",
    "l_svm = LinearSVC(labelCol='useful', regParam=10)\n",
    "\n",
    "# Fit the model\n",
    "l_svm_model = l_svm.fit(trainDF)\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"Train Logistic Regression accuracy: {(l_svm_model.evaluate(trainDF).accuracy) * 100:.2f}\")\n",
    "print(f\"Test Logistic Regression accuracy: {(l_svm_model.evaluate(testDF).accuracy) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation - using the \"best model\"\n",
    "\n",
    "Is our \"best model\" more biased towards recognizing one of the two classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_acc = lr_model.evaluate(testDF).accuracy\n",
    "l_svm_acc = l_svm_model.evaluate(testDF).accuracy\n",
    "best_model = l_svm_model if l_svm_acc > lr_acc else lr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = best_model.transform(testDF)\n",
    "predictions = (predictions.withColumn('label', predictions['useful'].cast('double')))\n",
    "metrics = MulticlassMetrics(predictions.select(['label', 'prediction']).rdd)\n",
    "\n",
    "cf_matrix = metrics.confusionMatrix().toArray()\n",
    "sb.heatmap(cf_matrix/np.sum(cf_matrix),\n",
    "           annot=True,\n",
    "           fmt='.1%',\n",
    "           cmap='Blues',\n",
    "           cbar=False,\n",
    "           xticklabels=['False', 'True'], yticklabels=['False', 'True'],\n",
    "           annot_kws={\n",
    "                'fontsize': 14\n",
    "            }).set(xlabel='Predicted class', ylabel='Actual class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Logistic Regression \n",
      "\n",
      "Precision:  0.39 \n",
      "Recall:  0.86 \n",
      "F1: 0.53\n",
      "Area under Precision-Recall curve:  0.37\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision(1.0)\n",
    "recall = metrics.recall(1.0)\n",
    "f1 = metrics.fMeasure(1.0)\n",
    "print('Best model:', 'SVM' if l_svm_acc > lr_acc else 'Logistic Regression', '\\n\\nPrecision: ', round(precision, 2), '\\nRecall: ', round(recall, 2), '\\nF1:', round(f1, 2))\n",
    "area_under_PR = BinaryClassificationMetrics(predictions.select(['label', 'prediction']).rdd).areaUnderPR\n",
    "print('Area under Precision-Recall curve: ', round(area_under_PR , 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark context underlying the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
