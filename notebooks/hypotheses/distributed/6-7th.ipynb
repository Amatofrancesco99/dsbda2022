{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0019afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../scripts')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf42b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spark located in /usr/local/spark/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/08/25 17:42:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/25 17:42:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "# Locate the Spark installation (add pyspark to sys.path, see https://github.com/minrk/findspark#readme)\n",
    "findspark.init()\n",
    "print(f'Using Spark located in {findspark.find()}.')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import BooleanType, DoubleType, LongType, StringType, StructField, StructType, ArrayType, IntegerType\n",
    "\n",
    "# Create or get the Spark session (singleton) and the underlying Spark context\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93267a",
   "metadata": {},
   "source": [
    "# Sixth and Seventh Hypothesis\n",
    "\n",
    "In the following notebook it will be analyzed the following two hypotheses:\n",
    " - **Are players loyal to a specific game notoriety level (no matter which one)?**\n",
    " - **Do players who mostly review famous games also enjoy niche ones?**\n",
    "\n",
    "*P.S:* The two hypotheses are considered together in this notebook since some data are shared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1ba15",
   "metadata": {},
   "source": [
    "## 6) Are players loyal to a specific game notoriety level (no matter which one)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b18114",
   "metadata": {},
   "source": [
    "### Data import, preprocessing & obtain useful metrics to perform the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07a95f",
   "metadata": {},
   "source": [
    "#### Import Reviews from HDFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11365288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "# Define a reasonable schema for the reviews dataset\n",
    "reviews_schema = StructType([\n",
    "    StructField('base_review_id', LongType(), True),\n",
    "    StructField('steamid', LongType(), True), \n",
    "    StructField('appid', LongType(), True),\n",
    "    StructField('voted_up', BooleanType(), True),\n",
    "    StructField('votes_up', LongType(), True),\n",
    "    StructField('votes_funny', LongType(), True),\n",
    "    StructField('weighted_vote_score', DoubleType(), True),\n",
    "    StructField('playtime_forever', LongType(), True),\n",
    "    StructField('playtime_at_review', LongType(), True),\n",
    "    StructField('num_games_owned', LongType(), True),\n",
    "    StructField('num_reviews', LongType(), True),\n",
    "    StructField('review', StringType(), True),\n",
    "    StructField('unix_timestamp_created', LongType(), True),\n",
    "    StructField('unix_timestamp_updated', LongType(), True)\n",
    "])\n",
    "\n",
    "# Read the reviews dataset from HDFS\n",
    "base_reviews_df = spark.read.csv(\n",
    "    path='hdfs://localhost:54310/final_project/data/base_reviews',\n",
    "    schema=reviews_schema,\n",
    "    escape='\"',\n",
    "    header=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    mode='FAILFAST',\n",
    "    multiLine=True,\n",
    "    unescapedQuoteHandling='STOP_AT_CLOSING_QUOTE'\n",
    ").to_pandas_on_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c87b3",
   "metadata": {},
   "source": [
    "#### Create games dataframe - contains the number of written reviews for a specific game (overall & only positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ea690e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>pos_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>195612</td>\n",
       "      <td>172188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000</td>\n",
       "      <td>59644</td>\n",
       "      <td>57716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105600</td>\n",
       "      <td>64284</td>\n",
       "      <td>63056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359550</td>\n",
       "      <td>67606</td>\n",
       "      <td>60965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271590</td>\n",
       "      <td>58734</td>\n",
       "      <td>44674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    appid  num_reviews  pos_reviews\n",
       "0     730       195612       172188\n",
       "1    4000        59644        57716\n",
       "2  105600        64284        63056\n",
       "3  359550        67606        60965\n",
       "4  271590        58734        44674"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain all reviews written for each game\n",
    "games_df = base_reviews_df.appid.value_counts().reset_index().rename(columns={\n",
    "    'index': 'appid',\n",
    "    'appid': 'num_reviews'\n",
    "})\n",
    "\n",
    "# Obtain all positive reviews written for each game\n",
    "pos_revs_per_game_df = base_reviews_df[base_reviews_df.voted_up].appid.value_counts().reset_index().rename(columns={\n",
    "    'index': 'appid',\n",
    "    'appid': 'pos_reviews'\n",
    "})\n",
    "games_df = games_df.merge(pos_revs_per_game_df, how='left').fillna(0).astype(int)\n",
    "games_df.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7095b4f",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38aa446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Utility functions \"\"\"\n",
    "\n",
    "def appid_to_num_reviews(appid):\n",
    "    \"\"\" Given the id of a game it gives its number of reviews \"\"\"\n",
    "    l = games_df[games_df.appid==appid].num_reviews.to_list()\n",
    "    return l[0] if l else 0\n",
    "\n",
    "def appid_to_notoriety(appid):\n",
    "    \"\"\" Given the id of a game it gives its notoriety level \"\"\"\n",
    "    l = games_df[games_df.appid==appid].notoriety.to_list()\n",
    "    return l[0] if l else 0\n",
    "\n",
    "def get_vote_val(userid, appid):\n",
    "    \"\"\" Obtain whether a player enjoyed a particular game or not \"\"\"\n",
    "    return small_reviews_df[(small_reviews_df.steamid == userid) & (small_reviews_df.appid == appid) ].voted_up.to_list()[0]\n",
    "\n",
    "def num_revs_to_label(num_rev:int)->str:\n",
    "    \"\"\" Get notoriety label from number of reviews \"\"\"\n",
    "    if num_rev < THRESH1:\n",
    "        return 'NICHE'\n",
    "    elif THRESH1 <= num_rev < THRESH2:\n",
    "        return 'KNOWN'\n",
    "    else:\n",
    "        return 'FAMOUS'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758bb81",
   "metadata": {},
   "source": [
    "#### Obtain for each game a notoriety level and a percentage of positive reviews\n",
    "\n",
    "The notoriety level is basically a measure of how much a game has been discussed in the small reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7c9050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14.0, 296.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = games_df.num_reviews.quantile([.25, .85])\n",
    "THRESH1 = s[.25]\n",
    "THRESH2 = s[.85]\n",
    "\n",
    "THRESH1, THRESH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7e282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>pos_reviews</th>\n",
       "      <th>notoriety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>195612</td>\n",
       "      <td>172188</td>\n",
       "      <td>FAMOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000</td>\n",
       "      <td>59644</td>\n",
       "      <td>57716</td>\n",
       "      <td>FAMOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105600</td>\n",
       "      <td>64284</td>\n",
       "      <td>63056</td>\n",
       "      <td>FAMOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359550</td>\n",
       "      <td>67606</td>\n",
       "      <td>60965</td>\n",
       "      <td>FAMOUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271590</td>\n",
       "      <td>58734</td>\n",
       "      <td>44674</td>\n",
       "      <td>FAMOUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    appid  num_reviews  pos_reviews notoriety\n",
       "0     730       195612       172188    FAMOUS\n",
       "1    4000        59644        57716    FAMOUS\n",
       "2  105600        64284        63056    FAMOUS\n",
       "3  359550        67606        60965    FAMOUS\n",
       "4  271590        58734        44674    FAMOUS"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "udf_num_revs_to_label = udf(lambda x: num_revs_to_label(x), StringType())\n",
    "\n",
    "games_df = games_df.to_spark().withColumn('notoriety', udf_num_revs_to_label(col('num_reviews'))).to_pandas_on_spark()\n",
    "games_df.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6ecac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>pos_reviews</th>\n",
       "      <th>notoriety</th>\n",
       "      <th>perc_pos_revs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>195612</td>\n",
       "      <td>172188</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>88.025275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000</td>\n",
       "      <td>59644</td>\n",
       "      <td>57716</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>96.767487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105600</td>\n",
       "      <td>64284</td>\n",
       "      <td>63056</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>98.089727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359550</td>\n",
       "      <td>67606</td>\n",
       "      <td>60965</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>90.176907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271590</td>\n",
       "      <td>58734</td>\n",
       "      <td>44674</td>\n",
       "      <td>FAMOUS</td>\n",
       "      <td>76.061566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    appid  num_reviews  pos_reviews notoriety  perc_pos_revs\n",
       "0     730       195612       172188    FAMOUS      88.025275\n",
       "1    4000        59644        57716    FAMOUS      96.767487\n",
       "2  105600        64284        63056    FAMOUS      98.089727\n",
       "3  359550        67606        60965    FAMOUS      90.176907\n",
       "4  271590        58734        44674    FAMOUS      76.061566"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df['perc_pos_revs'] = (games_df.pos_reviews / games_df.num_reviews) * 100\n",
    "games_df.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a888a0",
   "metadata": {},
   "source": [
    "#### Obtain for each user a list of reviewed games & keep the ones that had reviewed at least 3 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1735adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steamid</th>\n",
       "      <th>appid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960266219</td>\n",
       "      <td>[573170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960266231</td>\n",
       "      <td>[92800]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960267068</td>\n",
       "      <td>[453090]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960267185</td>\n",
       "      <td>[351490]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960267331</td>\n",
       "      <td>[61700, 730]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             steamid         appid\n",
       "0  76561197960266219      [573170]\n",
       "1  76561197960266231       [92800]\n",
       "2  76561197960267068      [453090]\n",
       "3  76561197960267185      [351490]\n",
       "4  76561197960267331  [61700, 730]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf_to_list = F.udf(lambda x:list(x), ArrayType(IntegerType()))\n",
    "\n",
    "users_reviewed_games = base_reviews_df.to_spark().groupby('steamid')\\\n",
    "                        .agg(F.collect_list('appid').alias('appid'))\\\n",
    "                        .withColumn('appid', udf_to_list(F.col('appid')))\\\n",
    "                        .to_pandas_on_spark()\n",
    "\n",
    "users_reviewed_games.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba7c5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steamid</th>\n",
       "      <th>appid</th>\n",
       "      <th>at_least_3_games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960269579</td>\n",
       "      <td>[4920, 980300, 252470]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960270050</td>\n",
       "      <td>[205100, 215280, 250320, 110800, 115800]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960270526</td>\n",
       "      <td>[253230, 571740, 578080, 730]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960272328</td>\n",
       "      <td>[287700, 203140, 418240, 578080]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960272398</td>\n",
       "      <td>[288160, 107200, 396750, 716630]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             steamid                                     appid  \\\n",
       "0  76561197960269579                    [4920, 980300, 252470]   \n",
       "1  76561197960270050  [205100, 215280, 250320, 110800, 115800]   \n",
       "2  76561197960270526             [253230, 571740, 578080, 730]   \n",
       "3  76561197960272328          [287700, 203140, 418240, 578080]   \n",
       "4  76561197960272398          [288160, 107200, 396750, 716630]   \n",
       "\n",
       "   at_least_3_games  \n",
       "0              True  \n",
       "1              True  \n",
       "2              True  \n",
       "3              True  \n",
       "4              True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import BooleanType\n",
    "\n",
    "udf_filter_at_least_3_games = udf(lambda x: (len(x) > 2), BooleanType())\n",
    "\n",
    "users_reviewed_games = users_reviewed_games.to_spark().withColumn('at_least_3_games', udf_filter_at_least_3_games(col('appid'))).to_pandas_on_spark()\n",
    "users_reviewed_least_3_games = users_reviewed_games[users_reviewed_games['at_least_3_games']]\n",
    "users_reviewed_least_3_games.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e45997c",
   "metadata": {},
   "source": [
    "#### Convert list of games to list of notoriety levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83b6a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 437, in dumps\n",
      "    return cloudpickle.dumps(obj, pickle_protocol)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle/cloudpickle_fast.py\", line 73, in dumps\n",
      "    cp.dump(obj)\n",
      "  File \"/usr/local/spark/python/pyspark/cloudpickle/cloudpickle_fast.py\", line 563, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "TypeError: cannot pickle '_thread.RLock' object\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not serialize object: TypeError: cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/serializers.py:437\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcloudpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPickleError:\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle/cloudpickle_fast.py:73\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     70\u001b[0m cp \u001b[38;5;241m=\u001b[39m CloudPickler(\n\u001b[1;32m     71\u001b[0m     file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/cloudpickle/cloudpickle_fast.py:563\u001b[0m, in \u001b[0;36mCloudPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m wrong_udf \u001b[38;5;241m=\u001b[39m udf(\u001b[38;5;28;01mlambda\u001b[39;00m x: [appid_to_notoriety(g, games_df) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m x], ArrayType(StringType()))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# wrong_udf = udf(lambda x: appid_to_notoriety(x[0]), StringType())\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# users_reviewed_least_3_games['notoriety'] = users_reviewed_least_3_games.appid.apply(lambda gs: [appid_to_notoriety(g) for g in gs])\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m users_reviewed_least_3_games \u001b[38;5;241m=\u001b[39m users_reviewed_least_3_games\u001b[38;5;241m.\u001b[39mto_spark()\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotoriety\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mwrong_udf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mto_pandas_on_spark()\n\u001b[1;32m      8\u001b[0m users_reviewed_least_3_games\u001b[38;5;241m.\u001b[39mto_spark()\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m5\u001b[39m)\u001b[38;5;241m.\u001b[39mtoPandas()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/udf.py:199\u001b[0m, in \u001b[0;36mUserDefinedFunction._wrapped.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, assigned\u001b[38;5;241m=\u001b[39massignments)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/udf.py:177\u001b[0m, in \u001b[0;36mUserDefinedFunction.__call__\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[0;32m--> 177\u001b[0m     judf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_judf\u001b[49m\n\u001b[1;32m    178\u001b[0m     sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(judf\u001b[38;5;241m.\u001b[39mapply(_to_seq(sc, cols, _to_java_column)))\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/udf.py:161\u001b[0m, in \u001b[0;36mUserDefinedFunction._judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_judf\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# It is possible that concurrent access, to newly created UDF,\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# will initialize multiple UserDefinedPythonFunctions.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# This is unlikely, doesn't affect correctness,\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# and should have a minimal performance impact.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_judf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_judf_placeholder\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/udf.py:170\u001b[0m, in \u001b[0;36mUserDefinedFunction._create_judf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m    168\u001b[0m sc \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msparkContext\n\u001b[0;32m--> 170\u001b[0m wrapped_func \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturnType\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m jdt \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mparseDataType(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturnType\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    172\u001b[0m judf \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mexecution\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mUserDefinedPythonFunction(\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, wrapped_func, jdt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevalType, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/udf.py:34\u001b[0m, in \u001b[0;36m_wrap_function\u001b[0;34m(sc, func, returnType)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_function\u001b[39m(sc, func, returnType):\n\u001b[1;32m     33\u001b[0m     command \u001b[38;5;241m=\u001b[39m (func, returnType)\n\u001b[0;32m---> 34\u001b[0m     pickled_command, broadcast_vars, env, includes \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_for_python_RDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonFunction(\u001b[38;5;28mbytearray\u001b[39m(pickled_command), env, includes, sc\u001b[38;5;241m.\u001b[39mpythonExec,\n\u001b[1;32m     36\u001b[0m                                   sc\u001b[38;5;241m.\u001b[39mpythonVer, broadcast_vars, sc\u001b[38;5;241m.\u001b[39m_javaAccumulator)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/rdd.py:2816\u001b[0m, in \u001b[0;36m_prepare_for_python_RDD\u001b[0;34m(sc, command)\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_for_python_RDD\u001b[39m(sc, command):\n\u001b[1;32m   2814\u001b[0m     \u001b[38;5;66;03m# the serialized command will be compressed by broadcast\u001b[39;00m\n\u001b[1;32m   2815\u001b[0m     ser \u001b[38;5;241m=\u001b[39m CloudPickleSerializer()\n\u001b[0;32m-> 2816\u001b[0m     pickled_command \u001b[38;5;241m=\u001b[39m \u001b[43mser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pickled_command) \u001b[38;5;241m>\u001b[39m sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mgetBroadcastThreshold(sc\u001b[38;5;241m.\u001b[39m_jsc):  \u001b[38;5;66;03m# Default 1M\u001b[39;00m\n\u001b[1;32m   2818\u001b[0m         \u001b[38;5;66;03m# The broadcast will have same life cycle as created PythonRDD\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m         broadcast \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mbroadcast(pickled_command)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/serializers.py:447\u001b[0m, in \u001b[0;36mCloudPickleSerializer.dumps\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    445\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not serialize object: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, emsg)\n\u001b[1;32m    446\u001b[0m print_exec(sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m--> 447\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mPicklingError(msg)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not serialize object: TypeError: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType\n",
    "\n",
    "wrong_udf = udf(lambda x: [appid_to_notoriety(g, games_df) for g in x], ArrayType(StringType()))\n",
    "# wrong_udf = udf(lambda x: appid_to_notoriety(x[0]), StringType())\n",
    "\n",
    "# users_reviewed_least_3_games['notoriety'] = users_reviewed_least_3_games.appid.apply(lambda gs: [appid_to_notoriety(g) for g in gs])\n",
    "users_reviewed_least_3_games = users_reviewed_least_3_games.to_spark().withColumn('notoriety', wrong_udf(col('appid'))).to_pandas_on_spark()\n",
    "users_reviewed_least_3_games.to_spark().limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030ccc3",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c84a6",
   "metadata": {},
   "source": [
    "#### Calculate the maximum loyalty of each user (that have reviewed at least 3 games) to a game notoriety level\n",
    "\n",
    "- **max_user_loyalty = (  max(user_reviewed_games[notoriety_level]) / reviewed_games  ) * 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24075ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "notoriety_games_users_reviewed_least_3_games = pd.DataFrame(users_reviewed_least_3_games['notoriety'])\n",
    "notoriety_games_users_reviewed_least_3_games.name = 'notoriety'\n",
    "notoriety_games_users_reviewed_least_3_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users_max_loyalty_level = notoriety_games_users_reviewed_least_3_games.notoriety.apply(lambda x : 100 * max(collections.Counter(x).values()) / sum(collections.Counter(x).values()) )\n",
    "users_max_loyalty_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0b2f18",
   "metadata": {},
   "source": [
    "#### Statistical test\n",
    "\n",
    "Are users loyal, for a M%, to one notoriety level (no matter which one)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b12c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the mean test\n",
    "statistics, p_value = utils.mean_test(users_max_loyalty_level, 75)\n",
    "\n",
    "print(f\"Mean test coefficient: {statistics:.3f} \\nP-value: {p_value:.3f}\")\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('\\nReject the null hypothesis')\n",
    "else:\n",
    "    print('\\nDo not reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b97097",
   "metadata": {},
   "source": [
    "We can notice that our hypothesis is true (and is statistically significant).<br> \n",
    "So we can say that people are loyal to review (and play) the 75% of same notoriety level games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9170ba8",
   "metadata": {},
   "source": [
    "## 7) Do players who mostly review famous games also enjoy niche ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53e36e",
   "metadata": {},
   "source": [
    "#### Obtain the loyalty level for famous & niche games, of players that have at least reviewed 3 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306336db",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_reviewed_least_3_games['loyalty_famous'] = users_reviewed_least_3_games.notoriety.apply( lambda gs : 100*collections.Counter(gs)['FAMOUS'] / sum(collections.Counter(gs).values())  )\n",
    "users_reviewed_least_3_games['loyalty_niche'] = users_reviewed_least_3_games.notoriety.apply( lambda gs : 100*collections.Counter(gs)['NICHE'] / sum(collections.Counter(gs).values())  )\n",
    "users_reviewed_least_3_games[['steamid', 'loyalty_famous','loyalty_niche']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b3f2f",
   "metadata": {},
   "source": [
    "#### Consider only people who are very loyal to famous games and that have at least played one niche game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_game_players = users_reviewed_least_3_games[ (users_reviewed_least_3_games.loyalty_famous > 55)  & (users_reviewed_least_3_games.loyalty_niche != 0 )]\n",
    "pop_game_players[['steamid', 'loyalty_famous','loyalty_niche']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267e7eb",
   "metadata": {},
   "source": [
    "#### Obtain the appreciation to niche games of players that are very loyal to famous games (and at least played one niche game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccd7bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "niche_appreciation_pop_game_players = pop_game_players.apply(lambda r : [get_vote_val(r.steamid, g) for g in r.appid if appid_to_notoriety(g) == 'NICHE'  ], axis=1).apply(lambda x : 100 * sum(x)/len(x))\n",
    "niche_appreciation_pop_game_players.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16899468",
   "metadata": {},
   "source": [
    "#### Statistical test\n",
    "\n",
    "Are users loyal to famous notoriety games also enjoying M% of niche ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3baa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics, p_value = utils.mean_test(niche_appreciation_pop_game_players, 60)\n",
    "\n",
    "print(f\"Mean test coefficient: {statistics:.3f} \\nP-value: {p_value:.3f}\")\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print('\\nReject the null hypothesis')\n",
    "else:\n",
    "    print('\\nDo not reject the null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aecb21",
   "metadata": {},
   "source": [
    "We can notice that our hypothesis is true (and is statistically significant).<br> \n",
    "So we can say that players loyal to famous notoriety games also enjoyed 60% of niche ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
